
# Бестолковые тесты versus качественное ПО. Часть 2. Что делать? 1

В [первой части](/part1) мы рассмотрели примеры тестов, из которых не все одинаково полезны. Здесь попробуем разобраться, что с этими тестами не так в принципе, и как всё-таки обеспечить качество ПО.

- [Бестолковые тесты versus качественное ПО. Часть 2. Что делать? 1](#бестолковые-тесты-versus-качественное-по-часть-2-что-делать-1)
  - [Что делать?](#что-делать)
    - [Качество ПО](#качество-по)
    - [Уровни абстракции](#уровни-абстракции)
    - ["Прямолинейность" кода (цикломатическая сложность)](#прямолинейность-кода-цикломатическая-сложность)
      - [1. Тестовые данные и "прямолинейность" кода](#1-тестовые-данные-и-прямолинейность-кода)
      - [2. Типы данных, уменьшающие цикломатическую сложность](#2-типы-данных-уменьшающие-цикломатическую-сложность)
      - [3. "Распрямление" if-boolean и match-enum](#3-распрямление-if-boolean-и-match-enum)
      - [4. "Рельсовое программирование" и цикломатическая сложность](#4-рельсовое-программирование-и-цикломатическая-сложность)
      - [5. Циклы vs. map/flatMap](#5-циклы-vs-mapflatmap)
    - [Классификация ошибок](#классификация-ошибок)
    - [Системный подход](#системный-подход)
- [Заключение](#заключение)


## Что делать?

Во-первых, раз тесты предполагается использовать для улучшения качества, надо определиться с критериями качества программного обеспечения. Ведь, если ориентироваться на % покрытия, то ряд вышеприведённых примеров будет разумным решением. 
Во-вторых, хорошо бы разобраться с тем, чем отличается алгоритмическая функция от табличной на фундаментальном уровне.
В-третьих, понять, как преобразовать требования к ПО в работающий код с использованием уровней абстракции.
В-четвёртых, проанализировать типы ошибок и понять роль тестов/типов в сфере защиты от ошибок. Что разумно требовать от тестов, и чего ожидать не стоит.
В-пятых, понять, какое отношение имеет системный подход к юнит-тестированию.

### Качество ПО

Качественная программа — (1) **достигает** (2) **требуемого результата** с соблюдением (3) заданных **ограничений** и (4) **минимизирует** (5) **целевую функцию**. Причём *ограничения* и *целевая функция* могут относиться не к самой программе, а к процессу её разработки.

Типичные ограничения (3):
- язык программирования/платформа;
- набор библиотек;
- стиль кодирования;
- ограничения предметной области (например, секретность);
- производительность (не ниже уровня);
- способности (знания, навыки) команды;
- ...

В качестве целевой функции (5) можно рассматривать:
- финансовые показатели:
  - инвестиции (время/стоимость разработки);
  - стоимость владения;
  - стоимость (потенциальная) последующего развития/расширения функционала;
- срок готовности ПО;
- количество строк кода;
- количество багов в течение опытного периода эксплуатации;
- производительность (время — деньги);
- задержки (latency);
- "степень удовлетворённости";
- ...

Сами тесты обычно не входят ни в целевую функцию, ни в ограничения. Т.е. тесты не являются целью разработки ПО, а могут служить средством достижения каких-либо целей. Например, с помощью теста можно в какой-то степени проверить, достигает ли программа требуемого результата при определённых входных значениях.

Иногда (на мой взгляд, ошибочно) тесты включают в ограничения: "покрытие тестами должно быть не ниже 70%" или "все возвращаемые ошибки должны быть проверены". А иногда (ещё, на мой взгляд, более ошибочно) — в целевую функцию: "код максимально покрыт тестами".

Можно ли выразить требуемый результат (2) в форме приёмочных тестов? Несмотря на общую веру в приёмочные тесты, требуемый результат, вообще говоря, невозможно описать одними лишь тестами. Программа по определению имеет бо́льшую общность, иначе её можно было бы заменить таблицей с параметрами приёмочных тестов.

Т.к. задача останова является NP-полной, то, по-видимому, нельзя ожидать от тестов и ответа на вопрос достижимости (1) какого-либо результата. Тем не менее, обычно факт завершения программы для каких-то входных значений рассматривают как косвенный признак, позволяющий надеяться, что программа завершается всегда.

### Уровни абстракции

В сложных системах, с которыми имеет дело человек, выделяются уровни абстракции. Повышение уровня абстракции — абстрагирование, понижение — конкретизация. 

В программных системах переход между уровнями абстракции происходит в момент реализации. Функция может служить наглядным примером связи между абстрактным и конкретным. Имя функции используется как короткая запись некоторого вычисления на более высоком уровне абстракции. А тело функции — подробная реализация этого же вычисления на более низком уровне абстракции.

Аналогичное явление возникает при конструировании составных структур данных из структур меньшего размера. Или при объединении данных и методов в объект. Или при создании библиотек, содержащих наборы инструментов для решения классов задач.

Вне программных систем также можно обнаружить уровни абстракции. К примеру, передача сигнала. На некотором уровне абстракции сигнал может иметь семантическую нагрузку. На следующем уровне семантическая нагрузка преобразуется в слова. Далее, при произнесении слова превращаются в звук (который также имеет временну́ю структуру — высота тона, паузы, интонация, n-граммы...). Звук, в свою очередь может быть оцифрован (следующий уровень абстракции), закодирован и передан посредством радиосвязи в виде радиосигнала (низший уровень абстракции).

Понимание абстрагирования и конкретизации крайне важно для разработки любых сложных систем, а в особенности для разработки программных систем, как наиболее сложных на сегодняшний день из создаваемых человеком. К сожалению, процесс абстрагирования/конкретизации неоднозначен и во многом имеет характер инженерного искусства. Есть много эвристических правил и рекомендаций, как надо и как не надо выполнять абстрагирование.

Каким образом качество ПО связано с абстракциями? Абстракции напрямую влияют на следующие характеристики ПО и процесса разработки ПО:
- приемлемость для команды (либо слишком низкоуровневые абстракции, либо наоборот, слишком сложные);
- скорость onboarding'а (нестандартные абстракции ещё надо освоить);
- рекрутинг; (Широко распространённые абстракции освоены многими разработчиками, присутствующими на рынке. Новые абстракции могут прокладывать себе дорогу через фреймворки и библиотеки.)
- стоимость (скорость/сложность) внесения изменений;
- защита от ошибок или наоборот, поощрение ошибок;
- размер кодовой базы;
- производительность программы;
- реализуемость (может оказаться, что некоторые сложные вещи невозможно реализовать на низком уровне абстракций за разумное время);
- и т.п.

Важно отметить, что абстракции в первую очередь необходимы людям. Компьютеры, по-всей видимости, могут работать на самых низких уровнях абстракции после удаления компилятором всех высокоуровневых аспектов.

### "Прямолинейность" кода (цикломатическая сложность)

#### 1. Тестовые данные и "прямолинейность" кода

TODO: посмотреть рекомендации из основополагающей книги по юнит-тестам

Основным современным подходом является использование разнообразных тестов (юнит-тесты, приёмочные тесты, функциональные тесты, интеграционные тесты, ...). Предполагается, что если тестовые данные подготовлены на основе требований, в значительной степени покрывают требования и код не противоречит тестовым данным, то код в какой-то степени соответствует предъявляемым требованиям.

Что означают обычные рекомендации о том, что тестовые данные должны быть "достаточно разнообразными", чтобы обеспечивать покрытие? В частности, какой смысл в рекомендации того, что необходимо тестировать "граничные случаи"? Если функция в каком-то смысле "прямолинейная", то проверка граничных случаев позволяет "обоснованно предполагать", что функция ведёт себя в соответствии с требованиями и в диапазоне значений между граничными случаями.

Что означает "прямолинейность"? На мой взгляд, свойство "прямолинейности" можно сформулировать следующим образом:

> Функция **прямолинейна** в некотором диапазоне входных значений в том случае, если для каждого значения из диапазона выполняется один и тот же код.

Несмотря на очевидную слабость определения, оно позволяет нам отделить наиболее проблематичный вид кода — условное ветвление. Если какое-то значение приводит к выбору другой ветви, то такое значение нарушает "прямолинейность". Поэтому и требуется дополнительное тестирование.

Существует понятие ["цикломатической сложности"](https://ru.wikipedia.org/wiki/Цикломатическая_сложность) программы — количества разных путей в графе потока управления. При цикломатической сложности, равной 1, программа, по-видимому, будет прямолинейной. Если мы хотим протестировать все возможные пути, то нам потребуется как минимум столько же отдельных тестов/кейсов, сколько существует путей, т.е. минимальное число тестов, обеспечивающих выполнение всего кода, будет равно цикломатической сложности.

#### 2. Типы данных, уменьшающие цикломатическую сложность

Интуитивное представление о "прямолинейности" некоторых функций может получить серьёзное подкрепление, если мы воспользуемся обобщёнными типами (дженериками) и условимся использовать только "чистые" функции.

Классический пример. Как может быть реализована функция, имеющая тип `f: [A] => A => A`?

<spoiler title="реализация">
```scala
val f: [A] => A => A = [A] => (a: A) => a
```
Иными словами — `identity`.  
</spoiler>

Т.к. функция должна работать для произвольных типов, то в ней не может быть какой-то специальной обработки отдельных значений. И автоматически такая функция соответствует определению "прямолинейной" на всём диапазоне возможных входных значений.

#### 3. "Распрямление" if-boolean и match-enum

В некоторых программах ещё встречаются boolean-флаги, напрямую управляющие ходом программы:

```scala
def adjusment(value: Int, useHiLevel: Boolean): Int =
  val level = if useHiLevel then hi else low
  level - value
```
Каждый флаг, используемый таким образом, может увеличить цикломатическую сложность программы в 2 раза. Чтобы протестировать `adjusment` потребуется написать два набора тестовых данных — со значением флага `true` и `false`. Кроме того, все boolean-переменные совместимы между собой. Из-за этого легко ошибиться, передав не тот флаг.

Чтобы сделать несовместимые boolean-значения, применяются специализированные enum-типы:
```scala
sealed trait LevelConfig
object LevelConfig:
  case object Hi extends LevelConfig
  case object Low extends LevelConfig

def adjusment(value: Int, levelConfig: LevelConfig): Int =
  val level = levelConfig match
    case LevelConfig.Hi  => hi
    case LevelConfig.Low => low
  level - value
```

Как избавиться от `if`-а внутри программы?

В ООП существует [паттерн "Стратегия"](https://ru.wikipedia.org/wiki/Стратегия_(шаблон_проектирования)), а в функциональном программировании — просто функция в качестве параметра или by-name параметр:
```scala
def adjusment(value: Int, level: => Int): Int =
  level - value
```
Условный оператор из основной программы переносится на уровень конфигурирования. Тем самым тестирование основной программы становится проще.

#### 4. "Рельсовое программирование" и цикломатическая сложность

Во многих задачах алгоритм решения оказывается последовательным, но при этом каждое действие может завершиться неудачей. В таком случае может применяться идея ["железнодорожно-ориентированного" программирования](https://habr.com/ru/articles/339606/). На Scala похожий результат достигается при использовании `Option` или `Either`:

```scala
def foo(aOpt: Option[Int]): Option[Int] =
  aOpt.flatMap(a => b(a)).flatMap(b => c(b))

def bar(aEither: Either[String, Int]): Either[String, Int] =
  aEither.flatMap(a => b(a)).flatMap(b => c(b))
```

Непосредственный расчёт цикломатической сложности не внушает оптимизма, потому что ветвления по-сути остались на месте. Однако, т.к. переход от Happy path к обработке ошибок реализован в библиотеке, то при тестировании достаточно проверить корректность лишь Happy path, а библиотека представит гарантию корректной передачи ошибок.

Таким образом, использование линейного кода, построенного с помощью монад, будет иметь эффективную цикломатическую сложность, равную 1, т.е. код будет "прямолинейным".

#### 5. Циклы vs. map/flatMap

Следующим оператором после `if`, вносящим вклад в цикломатическую сложность, является оператор цикла (`for`, `while`, ...).
Естественным способом распрямления кода является использование `.map`, `.flatMap` на коллекциях. Получающийся код будет прямолинейным. А все детали реализации, возможно содержащие циклы, будут на уровне библиотеки.

Очевидно, что не все циклы возможно переписать таким образом. Остаётся только максимально изолировать оставшиеся циклы и тщательно протестировать все граничные случаи.


### Классификация ошибок

В программах встречаются самые разные ошибки. Можно попытаться указать некоторые классы ошибок и оценить, насколько тесты и/или типы позволяют обнаруживать/предотвращать такие ошибки.

1. Ошибки, обнаруживаемые компилятором

   Есть несколько классов ошибок, которые мучают разработчиков на интерпретируемых языках с динамической типизацией:
   - опечатки;
   - вызов несуществующих функций;
   - неправильный набор аргументов функций;
   - несовместимые типы данных в одном выражении (причём некоторые языки в рантайме это проглатывают и втихаря выдают какой-то неожиданный результат);
   - использование неинициализированных переменных (при включенной опции `-Ysafe-init`);
   - ...


   Эти ошибки обнаруживаются в ходе выполнения именно той самой строчки кода, где они содержатся. По-видимому, это является причиной, по которой разработчики на таких языках пытаются обеспечить высокий процент покрытия строк кода — чтобы компенсировать отсутствие компилятора.

   Компилятор является мощным инструментом доказательства теорем о корректности программного обеспечения. Желательно по максимуму переносить все потенциальные проблемы на этап компиляции. Тем самым будут предотвращены многие ошибки времени исполнения и отпадёт необходимость писать избыточное количество тестов.

2. Ошибка на миллиард долларов (NPE)

   Похоже, что эта ошибка существует уже более полувека: [Null References: The Billion Dollar Mistake, Tony Hoare](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/). Суть проблемы заключается в том, что ссылочный тип данных помимо нормального значения, обладающего ожидаемым поведением, может иметь специальное значение `null`, обладающее неожиданным поведением. И многие языки скромно умалчивают (aka подразумевают по *умолчанию*) о том, что в любом месте программы в переменной типа `MyCuteObject` может прятаться какая-то неожиданность.

   По-видимому, обычные юнит-тесты не в силах предсказать NPE (`NullPointerException`). Если имеющиеся тесты проходят, то они и в дальнейшем будут проходить. Возможно, [мутационное тестирование](https://habr.com/ru/articles/334394/) или [property-based тестирование](https://habr.com/ru/companies/typeable/articles/570922/) как-то поможет.

   В Scala 3 (с включённой опцией `-Yexplicit-nulls`), как и в Kotlin, реализован подход, в котором `Null` представлен явным образом. В Java применяются аннотации `@NotNull` и статический анализ кода.
   Использование `Option` или явных `Null` типов, наряду с отказом от использования `null` в проекте, позволяет надеяться на то, что ошибка NPE окажется практически исключена.

3. Выход за пределы диапазона допустимых значений.

   Например, номер порта больше 65К. Или номер порта меньше 1024 для обычного пользователя. Или отрицательное значение там, где допускаются только неотрицательные. Или строковое значение, используемое в качестве модели `enum`, не входящее в список известных значений.

   [Refined-типы](https://habr.com/ru/articles/574080/) позволяют сформировать ограничения на значения примитивных типов и тем самым отделить валидацию от использования проверенных типов. Вместо строковых значений, очевидно, следует использовать собственно `enum`, специально придуманного для закрытого перечня взаимоисключающих вариантов.

   При попытке решить эту проблему с помощью тестов обычно рекомендуется на каждую границу диапазона написать два теста — положительный и отрицательный. Причём для одного параметра, возможно, придётся протестировать множество функций, которые с этим параметром работают. Объём работы, по-видимому, больше, чем при использовании refined-типов.

4. Попадание данных, не прошедших валидацию, в бизнес-логику.
   
   Здесь на помощь приходят [алгебраические типы данных](https://ru.wikipedia.org/wiki/Алгебраический_тип_данных) (тоже ADT, но не надо путать с абстрактными типами данных). Их особенность заключается в том, что они хорошо дружат с математикой и доказательством корректности программ.

   При успешной валидации мы должны сформировать тип, представляющий только корректные данные и исключающий возможность представления некорректных данных.

   Рассмотрим пример.

   В языке Go алгебраические типы данных не поддерживаются. Для сообщения об ошибках имеется "джентельменское соглашение" — возвращается пара `(A, error)` и значение проверяется тогда, когда `error` равен `nil`. К сожалению, такое соглашение соблюдается не всегда. Иногда на вызывающей стороне разработчик может проигнорировать ошибку. А иногда автор библиотеки может вернуть сразу и ошибку и значение. (Например, в стандартной библиотеке работы с файлами возвращается псевдо-ошибка EOF и, одновременно, прочитанные данные.)

   В языке Scala для похожей задачи можно воспользоваться типом `Either[error, A]`. Этот тип представляет алгебраическую сумму. Значением такого типа будет строго либо левая, либо правая часть. Тем самым исключаются невозможные комбинации — "и левая и правая часть", "нет ни левой, ни правой части".

   Пример [elm-css](https://www.youtube.com/watch?v=IcgmSRJHu_8&amp;ab_channel=elm-conf). В стандарте CSS предусмотрен ряд жёстких правил: 

    - `@charset` может быть указан не более одного раза;
    - `@import`, `@namespace` если имеются, должны быть указаны до всех декларация и следовать в этом порядке.
   
   Чтобы автоматически обеспечить невозможность представления невалидных CSS в коде, структура данных может иметь вид:

   ```scala
   case class ValidCSS(charset: Option[Charset], imports: List[Import], namespace: List[Namespace], declaration: List[Declaration])
   ```

   При этом в коде невозможно создать экземпляр, где было бы два charset'а. Тем самым исключаются как соответствующие ошибки, так и необходимость писать тесты.
   
5. Выход за границы массива в цикле.

   Если при обработке коллекций пользоваться высокоуровневым инструментарием наподобие `map`, `filter`, `fold`, ..., то необходимость пользоваться циклами практически отпадает. Тем самым исключается класс ошибок выхода за границы массива.

6. Ошибки неправильного понимания требований.

   Если разработчик понял требования неправильно, то и тесты и типы будут соответствовать пониманию разработчика. По-видимому, такие ошибки предотвратить трудно.

7. Примеры нарушения требований.

   Если нам известны примеры, то по ним легко можно написать тест, который будет это нарушение воспроизводить.

   Для исправления такого обнаруженного нарушения желательно понять, нельзя ли нарушенное требование представить на уровне типов данных. Если это возможно, то тем самым будут исключены все возможные нарушения требования в будущем.

8. Ошибки некорректного состояния.

   При использовании протоколов с состоянием, когда одна из сторон формирует состояние другой стороны цепочкой отдельных сообщений, и полагается на это сформированное состояние, потеря отдельного сообщения или логическая ошибка при формировании цепочки сообщений легко могут привести к тому, что вторая сторона будет иметь состояние, отличающееся от того, на которое рассчитывает первая сторона. Одним из вариантов защиты от таких ошибок является отказ от протоколов с состоянием и передача всей необходимой информации одним сообщением. Если тип этого сообщения разработать с учётом [принципа непредставимости невалидных данных](https://www.youtube.com/watch?v=3WE5L0OnqIU), то, по-видимому, этот класс ошибок будет исключён.

9.  Ошибки, вызванные дублированием параметров.

   Два компонента, связанных через TCP порт, должны быть сконфигурированы с одинаковым значением номера порта. Иначе они не смогут связаться друг с другом. Если конфигурации этих компонентов независимы, то номер порта окажется продублирован. В дальнейшем при изменении конфигурации легко упустить необходимость согласованного изменения во всех точках, использующих этот же номер порта. Такую проблему можно искоренить пользуясь принципом DRY на уровне всей системы. Номер порта должен быть указан единственный раз в конфигурации системы, а конфигурация связанных компонентов должна выводиться автоматически. (Подробнее: [Компилируемая конфигурация распределённой системы](https://habr.com/ru/companies/primetalk/articles/447694/).)

10. Несовместимость версий.

   Есть популярное поверье в [semver](https://github.com/semver/semver/pull/414) — якобы достаточно следовать простым правилами инкремента номеров версий, и приложение будет автоматически согласовано. К сожалению, даже автоматический переход на следующую минорную версию зависимости вполне может привести к непредсказуемым последствиям. Особенно, если автоматически подтягиваются транзитивные зависимости.

   Наилучших результатов по стабильности мне приходилось наблюдать в тех проектах, где версии библиотек были жёстко зафиксированы. Более того, сам исходный код библиотек был закэширован в корпоративном репозитории. Несмотря на то, что переход на свежии версии давался с некоторым трудом, однако воспроизводимость сборки и результатов тестов была 100%.

   Одним из неплохих промежуточных вариантов для компаний, в которых работает несколько команд, может служить понятие "платформы" — совокупности зафиксированных версий библиотек, которой даётся собственный номер версии (что-то похожее может быть представлено с помощью [Maven BOM](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#bill-of-materials-bom-poms)). В этом случае отдельные микросервисы, взаимодействующие между собой, должны как минимум использовать одну версию "платформы".

   Ещё одним вариантом, который может использоваться в достаточно тесно интегрированных командах, является использование единой согласованной кодовой базы для всех микросервисов. При этом, если гарантировать развёртывание всех микросервисов из одной версии исходного кода, проблема несовместимости версий будет полностью 
   ликвидирована. Такого эффекта можно, например, достичь, если компилировать единый бинарный файл, роль которого выбирается при запуске микросервиса.

### Системный подход

Как только мы начинаем говорить о тестировании, возникает вопрос, где провести границу того, что мы будем тестировать. Чем отличается *юнит-тестирование* от *интеграционного*? Как отделить зависимости?

На мой взгляд, подходящий понятийный аппарат даёт *системный подход*. Разрабатываемая программа, работающая в каком-то окружении, является системой (*runtime-системой*), состоящей из взаимосвязанных компонентов. Каждый компонент в свою очередь представляется подсистемой, состоящей из компонентов следующего уровня.

Деление программы на системы/компоненты неоднозначно и зависит от точки зрения. Например, ту же программу, при взгляде на исходный код, можно разделить на библиотеки, пакеты, отдельные файлы. Связи между такими компонентами будут представлены через явный или неявный import. В некоторых случаях один и тот же программный код может использоваться и при запуске большой системы в качестве подсистемы, и в качестве системы верхнего уровня. Например, подсистема импорта данных вполне может работать и автономно.

Несмотря на то, что юнит-тесты зачастую организуются вокруг файлов с программным кодом, их задачей является тестирование компонента будущей runtime-системы. Runtime-система обычно представляет собой программный код + конфигурация (т.е. программа, запущенная в определённой конфигурации). Поэтому одной из задач, стоящих перед юнит-тестами, является инициализация используемых компонентов таким образом, чтобы заставить программный код работать похожим образом, как в действующей системе, в тех же режимах. 

*Интеграционным тестом*, насколько я могу судить, называют тест системы бо́льшего размера, чем помещается в одном файле. В сущности, интеграционным тестом можно было бы называть юнит-тест, тестирующий достаточно большую подсистему (большой "юнит"). Для целей тестирования конфигурация такой подсистемы (SUT — system under test) может отличаться от конфигурации рабочей системы. Более того, может быть собрана новая тестовая система с совершенно другой конфигурацией, включающей как компоненты будущей рабочей системы, так и другие компоненты, не используемые в рабочей системе. Например, какие-то компоненты могут быть заменены на их упрощённые версии (заглушки, тестовые реализации интерфейсов, моки, менее производительные сервисы), часть компонентов отключена, а оставшиеся сконфигурированы для работы в этих новых условиях. 

Ценность создаваемой тестовой системы заключается в том, что хотя бы часть компонентов работает в режимах, похожих на рабочие. Разработка же самой тестовой системы и всех вспомогательных компонентов, их поддержка, может быть отнесена к накладным расходам. По-видимому, желательно добиваться целей тестирования минимальными усилиями.

Возможность создания таких тестовых систем и конфигураций обеспечивается гибкостью принятых проектных решений. Например, если компоненты напрямую закодированы единственным образом ("захардкожены"), то выбрать другую реализацию компонента не получится. Если же связи между компонентами хорошо определены (с помощью интерфейсов/API), то можно будет собрать любую тестовую конфигурацию.

Собственно процесс выделения и обособления компонентов, формализации связей между ними, уже улучшает качество разрабатываемой системы, упрощает её развитие, увеличивает гибкость поддерживаемых конфигураций.

# Заключение

В этой части рассмотрены некоторые соображения, которые позволяют подойти к тестам с рациональных позиций. Если во главу угла поставлено качество программного обеспечения, то тесты являются лишь одним из компонентов процесса разработки. Значительно большее влияние на качество могут оказать типы данных.

Под качеством ПО понимается оптимизация целевой функции при соблюдении ограничений (соответствие требованиям). Причём в качестве целевой функции может выступать и стоимость разработки. А так как на разработку и поддержку тестов уходят усилия, то небезынтересен вопрос о том, каким образом обеспечить качество ПО при минимальном количестве тестов. Например, за счёт использования типов данных, исключающих некоторые классы ошибок.
